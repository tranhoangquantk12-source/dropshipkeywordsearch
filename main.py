import os
import json
import gspread
import requests
import time
import sys
from oauth2client.service_account import ServiceAccountCredentials

# --- C·∫§U H√åNH ---
SPREADSHEET_ID = "1uvjEg0XtG_Q8jNjPVQ6FP_9cIvqxyur-I-PHNggUy5s"
SHEET_KW_NAME = "kw"
SHEET_PUB_NAME = "Publisher"
SHEET_ART_NAME = "Article" # Sheet m·ªõi cho flow 2

# Blacklist Domains
EXCLUDE_DOMAINS = [
    "youtube.com", "shopify.com", "autods.com", "omnisend.com", 
    "reddit.com", "quora.com", "coursera.org", "classcentral.com", 
    "trueprofit.io", "beprofit.co", "facebook.com", "instagram.com", 
    "tiktok.com", "threads.com", "x.com", "cursa.app", 
    "coursesity.com", "scribd.com", "alison.com", "udemy.com" , "zendrop.com",
]

def get_google_sheet_client():
    creds_json = os.environ.get("GCP_SA_KEY")
    if not creds_json:
        raise Exception("Kh√¥ng t√¨m th·∫•y bi·∫øn m√¥i tr∆∞·ªùng GCP_SA_KEY.")
    
    creds_dict = json.loads(creds_json)
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    client = gspread.authorize(creds)
    return client

def search_serper(query, api_key, num_results=10):
    """H√†m search core: G·ªçi API v√† l·ªçc domain r√°c"""
    url = "https://google.serper.dev/search"
    payload = json.dumps({"q": query, "num": 30}) # L·∫•y d∆∞ ƒë·ªÉ l·ªçc
    headers = {'X-API-KEY': api_key, 'Content-Type': 'application/json'}

    try:
        response = requests.request("POST", url, headers=headers, data=payload)
        data = response.json()
        
        if "organic" not in data:
            return []

        clean_results = []
        count = 0
        for item in data["organic"]:
            link = item.get("link")
            if not link: continue
            
            domain = link.split("//")[-1].split("/")[0].lower()
            is_blocked = False
            for blocked in EXCLUDE_DOMAINS:
                if blocked in domain:
                    is_blocked = True
                    break
            
            if not is_blocked:
                clean_results.append(link)
                count += 1
            if count == num_results:
                break     
        return clean_results

    except Exception as e:
        print(f"L·ªói Serper API khi search '{query}': {e}")
        return []

def process_and_save(keywords, target_sheet_obj, api_key, flow_name):
    """
    H√†m x·ª≠ l√Ω logic chung cho m·ªçi lu·ªìng:
    Input: List Keywords -> Search -> Output: Ghi URL v√†o Target Sheet
    """
    print(f"\nüöÄ B·∫ÆT ƒê·∫¶U {flow_name}...")
    print(f"-> S·ªë l∆∞·ª£ng keyword c·∫ßn ch·∫°y: {len(keywords)}")
    
    if not keywords:
        print("-> Kh√¥ng c√≥ keyword n√†o. Skip.")
        return

    data_buffer = []
    
    for kw in keywords:
        print(f"   Searching: {kw}")
        urls = search_serper(kw, api_key)
        
        for url in urls:
            # Ch·ªâ l·∫•y URL, m·ªói URL 1 d√≤ng, 1 c·ªôt
            data_buffer.append([url])
            
        time.sleep(0.5) # Delay nh·∫π tr√°nh spam

    if data_buffer:
        print(f"-> ƒêang ghi {len(data_buffer)} URLs v√†o sheet...")
        target_sheet_obj.append_rows(data_buffer)
        print(f"‚úÖ {flow_name}: HO√ÄN TH√ÄNH.")
    else:
        print(f"‚ö†Ô∏è {flow_name}: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu m·ªõi n√†o.")

def main():
    print("--- STARTING DUAL FLOW JOB ---")
    
    try:
        # 1. Init Connections
        client = get_google_sheet_client()
        sh = client.open_by_key(SPREADSHEET_ID)
        
        # L·∫•y c√°c sheet c·∫ßn thi·∫øt
        kw_sheet = sh.worksheet(SHEET_KW_NAME)
        pub_sheet = sh.worksheet(SHEET_PUB_NAME)
        art_sheet = sh.worksheet(SHEET_ART_NAME) # Sheet Article
        
        serper_api_key = os.environ.get("SERPER_API_KEY")
        if not serper_api_key:
             raise Exception("Thi·∫øu SERPER_API_KEY")

        # 2. CHU·∫®N B·ªä D·ªÆ LI·ªÜU ƒê·∫¶U V√ÄO
        
        # --- LU·ªíNG 1: Keyword c·ªôt A (Article) ---
        # L·∫•y c·ªôt 1, b·ªè header d√≤ng 1
        raw_col_a = kw_sheet.col_values(1)[1:] 
        keywords_group_a = [k for k in raw_col_a if k.strip()]

        # --- LU·ªíNG 2: Keyword c·ªôt B (Publisher) ---
        # L·∫•y c·ªôt 2, b·ªè header d√≤ng 1
        raw_col_b = kw_sheet.col_values(2)[1:] 
        keywords_group_b = [k for k in raw_col_b if k.strip()]

        # 3. TH·ª∞C THI C√ÅC LU·ªíNG
        
        # Ch·∫°y lu·ªìng cho Article (Input A -> Output Article)
        process_and_save(keywords_group_a, art_sheet, serper_api_key, flow_name="FLOW 1 [Article]")

        # Ch·∫°y lu·ªìng cho Publisher (Input B -> Output Publisher)
        process_and_save(keywords_group_b, pub_sheet, serper_api_key, flow_name="FLOW 2 [Publisher]")

    except Exception as e:
        print(f"\n‚ùå L·ªñI H·ªÜ TH·ªêNG: {e}")
        sys.exit(1)

    print("\n--- JOB FINISHED SUCCESSFULLY ---")

if __name__ == "__main__":
    main()
